# ğŸ¦œ Agentic RAG Chatbot with Ollama & LangChain

## ğŸ“Œ Overview
This project is a **local Retrieval-Augmented Generation (RAG) chatbot** that:
- Scrapes relevant knowledge from **Wikipedia** using **Bright Data**.
- Creates embeddings using **Ollama**.
- Stores knowledge in a **Chroma vector database**.
- Uses **LangChain** to orchestrate retrieval and answer generation.
- Runs **completely locally** â€” no API calls to external LLM services.

## ğŸš€ Features
- **Local LLM Inference** using Ollama.
- **Local Embeddings** with Ollama models.
- **Efficient Knowledge Retrieval** from a Chroma vector store.
- **Wikipedia Scraping** with Bright Data based on custom keywords.
- **Interactive Chat UI** powered by Streamlit.
- **Conversation History Awareness** for follow-up questions.

## ğŸ› ï¸ Tech Stack
- **Python** â€“ Core programming language.
- **LangChain** â€“ Orchestration of retrieval and chat model.
- **Ollama** â€“ For both chat model and embedding model.
- **Bright Data** â€“ Web scraping Wikipedia articles.
- **Chroma** â€“ Local vector database for document storage.
- **Streamlit** â€“ Web app interface.

