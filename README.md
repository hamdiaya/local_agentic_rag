# 🦜 Agentic RAG Chatbot with Ollama & LangChain

## 📌 Overview
This project is a **local Retrieval-Augmented Generation (RAG) chatbot** that:
- Scrapes relevant knowledge from **Wikipedia** using **Bright Data**.
- Creates embeddings using **Ollama**.
- Stores knowledge in a **Chroma vector database**.
- Uses **LangChain** to orchestrate retrieval and answer generation.
- Runs **completely locally** — no API calls to external LLM services.

## 🚀 Features
- **Local LLM Inference** using Ollama.
- **Local Embeddings** with Ollama models.
- **Efficient Knowledge Retrieval** from a Chroma vector store.
- **Wikipedia Scraping** with Bright Data based on custom keywords.
- **Interactive Chat UI** powered by Streamlit.
- **Conversation History Awareness** for follow-up questions.

## 🛠️ Tech Stack
- **Python** – Core programming language.
- **LangChain** – Orchestration of retrieval and chat model.
- **Ollama** – For both chat model and embedding model.
- **Bright Data** – Web scraping Wikipedia articles.
- **Chroma** – Local vector database for document storage.
- **Streamlit** – Web app interface.

